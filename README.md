# What did Ilya read?
> My self personal study course on the papers Ilya Sutskever recommended to John Carmack to help him grok Language Models

# AI Fundamentals Reading List (Sutskever's Recommendations + Additions)

This reading list represents a comprehensive overview of fundamental AI concepts and breakthrough papers that shaped the field. The list is particularly well-curated as it covers key areas like:

- Neural network architectures (Transformers, LSTMs, ResNets)
- Scaling and optimization techniques
- Natural language processing
- Computer vision
- Theoretical foundations
- Practical applications

## Core Foundation Papers
- [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)
- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [ImageNet Classification with Deep Convolutional Neural Networks](https://sing.stanford.edu/curis-fellowships/rh/vision-dnn.pdf)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

## Advanced Architecture Papers
- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
- [Neural Turing Machines](https://arxiv.org/abs/1410.5401)
- [Pointer Networks](https://arxiv.org/abs/1506.03134)
- [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)

## Scaling & Optimization Papers
- [GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://arxiv.org/abs/1811.06965v5)
- [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)
- [Recurrent Neural Network Regularization](https://arxiv.org/abs/1409.2329)

## Theoretical Foundation Papers
- [The First Law of Complexodynamics](https://scottaaronson.blog/?p=762)
- [Kolmogorov Complexity and Algorithmic Randomness](https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf)
- [A Tutorial Introduction to the Minimum Description Length Principle](https://arxiv.org/pdf/math/0406077)

## Blog Posts & Tutorials
- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [CS231n: Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/)

The CS231n course notes serve as an excellent practical foundation before diving into the papers. For someone starting out, I recommend beginning with the blog posts (Karpathy's RNN post, Olah's LSTM post) before tackling the more technical papers.

This approach of first understanding the high-level concepts before diving into mathematical details is sound. It will help build intuition before exploring the deeper theoretical foundations.
